{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Npj0LTWXtre4"},"outputs":[],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylNroZCNvViA"},"outputs":[],"source":["%pip install -U -q tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mg544VCitwmQ"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import backend as K\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_orlzETmuKC2"},"outputs":[],"source":["%pip install image-dataset-loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fhibj06RuhDt"},"outputs":[],"source":["from image_dataset_loader import load\n","\n","basepath=\"drive/MyDrive/Deepfakes/Data/Task_1\"\n","train_data_dir = basepath + '/development'\n","validation_data_dir =  'drive/MyDrive/Deepfakes/Data/Task_2_3/evaluation'\n","\n","# dimensions of our images.\n","img_width, img_height = 436, 500\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","# test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","data_with_aug = ImageDataGenerator(horizontal_flip=True,\n","                                   vertical_flip=False,\n","                                   rescale=1./255,\n","                                  validation_split=0.2)\n","\n","val = data_with_aug.flow_from_directory(validation_data_dir,\n","                                          class_mode=\"binary\",\n","                                          target_size=(224, 224),\n","                                          batch_size=32,\n","                                          subset=\"validation\"\n","                                          )\n","\n","train = data_with_aug.flow_from_directory(train_data_dir,\n","                                          class_mode=\"binary\",\n","                                          target_size=(224, 224),\n","                                          batch_size=32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k26gjf-f9BzL"},"outputs":[],"source":["vgg16_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__B3PEam9BwU"},"outputs":[],"source":["vgg16_model.output[-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAzdGlKO9Bpd"},"outputs":[],"source":["model = Sequential([vgg16_model,\n","                     tf.keras.layers.GlobalAveragePooling2D(),\n","                     Dense(512, activation = \"relu\"),\n","                     tf.keras.layers.BatchNormalization(),\n","                     Dense(128, activation = \"relu\"),\n","                     Dense(2, activation = \"softmax\")])\n","# We will be training only our dense layers not the entire VGG16 model\n","model.layers[0].trainable = False\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=\"accuracy\")\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SQVXi5ib9Bis"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","24/24 [==============================] - 518s 21s/step - loss: 0.7622 - accuracy: 0.5289\n","Epoch 2/20\n","24/24 [==============================] - 499s 21s/step - loss: 0.5610 - accuracy: 0.7526\n","Epoch 3/20\n","24/24 [==============================] - 491s 20s/step - loss: 0.4756 - accuracy: 0.8158\n","Epoch 4/20\n","24/24 [==============================] - 481s 20s/step - loss: 0.4211 - accuracy: 0.8671\n","Epoch 5/20\n","24/24 [==============================] - 472s 20s/step - loss: 0.3710 - accuracy: 0.8697\n","Epoch 6/20\n","24/24 [==============================] - 473s 20s/step - loss: 0.3257 - accuracy: 0.9118\n","Epoch 7/20\n","24/24 [==============================] - 466s 19s/step - loss: 0.2955 - accuracy: 0.9211\n","Epoch 8/20\n"," 2/24 [=\u003e............................] - ETA: 7:36 - loss: 0.2901 - accuracy: 0.9375"]}],"source":["history =  model.fit(train,\n","                    epochs=20\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbU830VE9VFM"},"outputs":[],"source":["predictions = model.predict(val)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34eb8-Xi9WD8"},"outputs":[],"source":["scores = model.evaluate(val, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwVB2MJaHzOt"},"outputs":[],"source":["model = Sequential([\n","    model,\n","    Flatten(),\n","    Dense(1024, activation='relu'),\n","    Dropout(0.5),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(256, activation='relu'),\n","    Dropout(0.5),\n","    Dense(2, activation='softmax')\n","])\n","\n","# We will be training only our dense layers not the entire VGG16 model\n","model.layers[-5].trainable = True\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=\"accuracy\")\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7SyWQXIH5RZ"},"outputs":[],"source":["history = model.fit(train,\n","                    epochs=20,\n","                    validation_data=val)\n","\n","# Calculate the loss and accuracy on the validation set\n","val_loss, val_acc = model.evaluate(val)\n","print('Validation loss:', val_loss)\n","print('Validation accuracy:', val_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnwzTRv9H65P"},"outputs":[],"source":["predictions = model.predict(val)\n","scores = model.evaluate(val, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlAP4CRUwVS2"},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","_, _, val_labels = load(validation_data_dir, \"inception\", target_size=(224, 224), batch_size=32)\n","\n","\n","faces_pred = model.predict(val)\n","faces_pred = (np.amax(faces_pred, axis = 1)-0.5)*2\n","val_labels = np.argmax(val_labels, axis = 1)\n","print(faces_pred)\n","\n","\n","fpr, tpr, thresholds = roc_curve(val_labels, faces_pred)\n","\n","# Compute area under the curve (AUC)\n","roc_auc = auc(fpr, tpr)\n","\n","# Plot ROC curve\n","plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n","plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guess')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}